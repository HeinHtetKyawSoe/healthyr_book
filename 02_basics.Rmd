---
output: html_document
editor_options: 
  chunk_output_type: inline
---
# R Basics

```{r, include = FALSE}
library(tidyverse)
```


The aim of this chapter is to familiarise you with how R works. 
We will read in data and start basic manipulations. 
We will be working with a shorter version of the Global Burden of Disease dataset that we met earlier. 


## Getting help

RStudio has a built in Help tab. 
To use the Help tab, click your cursor on something in your code (e.g. `read_csv()`) and press F1. This will show you the definition and some examples. 
However, the Help tab is only useful if you already know what you are looking for but can't remember exactly how it works. 
For finding help on things you have not used before, it is best to Google it. 
R has about 2 million users so someone somewhere has had the same question or problem.


## Objects and functions

The two fundamental concepts to understand about statistical programming are objects and functions. 
As usual, in this book, we prefer introducing new concepts using specific examples first.
And then define things in general terms after examples.

The most common data object you will be working with is a table - so something with rows and columns. 
It should be regular, e.g., the made-up example in Table \@ref(tab:chap2-tab-examp1).
^[Regular does not mean it can't have missing values.
Missing values are denoted `NA` which stands for either `Not available` or `Not applicable`. 
In same contexts, these things can have a different meaning. 
For example, since `var2` is `NA` for all male subjects, it may mean "Not applicable", i.e. something that can only be measured in females.
Whereas in `var3`, `NA` is more likely to mean "Not available" so real missing data, e.g. lost to follow-up.]

```{r chap2-tab-examp1, echo = FALSE}

mydata = tibble(id   = 1:4,
       sex  = c("Male", "Female", "Female", "Male"),
       var1 = c(4, 1, 2, 3),
       var2 = c(NA, 4, 5, NA),
       var3 = c(2, 1, NA, NA))

mydata %>% 
  knitr::kable(booktabs = TRUE, caption = "Example of a table (=tibble once read into R), including missing values denoted NA (Not applicable/Not available).") %>% 
  kableExtra::kable_styling(font_size=8)

```


A table can live anywhere: on paper, in a Spreadsheet, in an SQL database, or it can live in your R Session's Environment. 
And yes, R sessions are as fun as they sound, almost as fun as, e.g., music sessions. 
We usually initiate and interface R using RStudio, but everything we talk about here (objects, functions, sessions, environment) also work when RStudio is not available, but R is. 
This can be the case if you are working on a supercomputer that can only serve the R Console, and not an RStudio IDE (reminder from first chapter: Integrated Development Environment). 
So, regularly shaped data in rows and columns is called table when it lives outside R, but once you read it into R (import it), we call it a tibble.
^[There used to be an older version of tables in R - they are called data frames. 
In most cases, `data frames` and `tibbles` work interchangeably (and both are R objects), but `tibbles` are newer and better. 
Another great alternative to base R's `data frames` are `data tables`. 
In this book, and for most of our day-to-day work these days, we use `tibbles` though.]
When you are in one of your very cool R sessions and read in some data, it goes into this session's Environment. Everything in your Environment needs to have a name as you can have multiple tibbles going on at the same time (`tibble` is not a name, it is the class of an object). To keep our code examples easy to follow, we call our example tibble `mydata`. In real analysis, you should give your tibbles meaningful names, e.g., `patient_data`, `lab_results`, `annual_totals`, etc.

So, the tibble named `mydata` is example of an object that can be in the Environment of your R Session:

```{r}
mydata
```

An example of a function that can be applied on numeric data is `mean()`. 
R functions always have round brackets after their name. 
This is for two reasons. 
First, to easily differentiate them from objects - which don't have round brackets after their name. 
Second, and more important, we can put arguments in these brackets. 
Arguments can also be thought of as input, and in data analysis, the most common input for a function is data: we need to give `mean()` some data to average over. 
It does not make sense (nor will it work) to feed it the whole tibble that has multiple columns, including patient IDs and a categorical variable (`sex`). 
To quickly extract a single column, we use the `$` symbol like this:

```{r}
mydata$var1
```

You can ignore the `## [1]` at the beginning of the extracted values - this is something that becomes more useful when printing multiple lines of data as the number in the square brackets keeps count on how many values we are seeing.

We can then use `mydata$var1` as the first argument of `mean()` by putting it inside its brackets:

```{r}
mean(mydata$var1)
```

Which tells us that the mean of `var1` (`r mydata$var1`) is `r mean(mydata$var1)`.
In this example, `mydata$var1` is the first and only argument to `mean()`.
But what happens if we try to calculate the average value of `var2` (`r mydata$var2`)?

```{r}
mean(mydata$var2)
```

We get an `NA` ("Not applicable").
We would expect to see an `NA` if we tried to, for example, calculate the average of `sex`:

```{r, error=TRUE}
mean(mydata$sex)
```

In fact, in this case, R also gives us a pretty clear warning suggesting it can't compute the mean of an argument that is not numeric or logical. 
The sentence actually reads pretty fun, as if R was saying it was not logical to calculate the mean of something that is not numeric. 
But what R is actually saying that it is happy to calculate the mean of two types of variables: numerics or logicals, but what you have passed it is neither.
^[Logical is a data type with two potential values: TRUE or FALSE.
We will come back to data types shortly.]

So `mean(mydata$var2)` does not return an Error, but it also doesn't return the mean of the numeric values included in this column. 
That is because the column includes missing values (`NAs`), and R does not want to average over NAs implicitly.
It is being cautious - what if you didn't know there were missing values for some patients?
If you wanted to compare the means of `var1` and `var2` without any further filtering, you would be comparing samples of different size. 
Which might be fine if the sample sizes are sufficiently representative and the values are missing at random. 
Therefore, if you decide to ignore the NAs and want to calculate the mean anyway, you can do so by adding another argument to `mean()`:

```{r}
mean(mydata$var2, na.rm = TRUE)
```

Adding `na.rm = TRUE` tells R that you are happy for it to calculate the mean of any existing values (but to remove - `rm` - the `NA` values).
This 'removal' excludes the NAs from the calculation, it does not affect the actual tibble (`mydata`) holding the dataset. 
R is case sensitive, so it has look exactly how the function expects it, so `na.rm`, not `NA.rm` etc. 
There is, however, no need to memorise how the arguments of functions are exactly spelled - this is what the Help tab (press `F1` when the cursor is on the name of the function) can remind you of. 
Functions' help pages are built into R, so an internet connection is not required for this.

> Make sure to separate multiple arguments with commas, or R will give you an error of `Error: unexpected symbol`.

Finally, some functions do not need any arguments to work.
A good example is the `Sys.time()` which returns the current time and date. 
This is very useful when using R to generate and update reports automatically.
Including this means you can always be clear on when the results were last updated.

```{r}
Sys.time()
```

To summarise, objects and functions work hand in hand. 
Objects are both an input as well as the output of a function (what the function returns). 
The data values input into a function are usually its first argument, further arguments can be used to specify a function's behaviour. 
When we say "the function returns", we are referring to its output (or an Error if it's one of those days).
The returned object can be different to its input object.
In our `mean()` examples above, the input object was a column (`mydata$var1`: `r mydata$var1`), whereas the output was a single value: `r mean(mydata$var1)`.

## Working with Objects

To create a new object into our Environment we use the equals sign:

```{r}
a = 103
```

This reads: the variable `a` is assigned value `r a`. You know that the assignment worked when it shows up in the Environment tab.
If we now run `a` just on its own, it gets printed back to us:

```{r}
a
```

Similarly, if we run a function without assignment to a variable, it gets printed but not saved in your Environment:

```{r}
seq(15, 30)
```

`seq()` is a function that creates a sequence of numbers (+1 by default) between the two arguments you pass to it in its brackets. 
We can assign the result of `seq(15, 30)` into a variable, let's call it `example_sequence`:

```{r}
example_sequence = seq(15, 30)
```

Doing this creates `example_sequence` in our Environment, but it does not print it. 

> If you save the results of an R function in a variable, it does not get printed. If you run a function without the assignment (`=`), its results get printed, but not saved in a variable.

You can call your variables (where you assigns new objects or the output of functions in) pretty much anything you want, as long as it starts with a letter. 
It can then include numbers as well, for example, we could have named the new variable `sequence_15_to_30`.
Spaces in variable names are not easy to work with, we tend to use underscores in their place, but you could also use capitalisation, e.g. `exampleSequence = seq(15, 30)`.

Finally, R doesn't mind overwriting an existing variable, for example (notice how we then include the variable on a new line to get it printed as well as overwritten):

```{r}
example_sequence = example_sequence/2

example_sequence
```


>Note that many people use `<-` instead of `=`. 
>They mean the same thing in R: both `=` and `<-` save what is on the right into the variable name on the left. 
>There is also a left-to-right operator: `->`.

## Pipe - `%>%` 

The pipe - denoted `%>%` - is probably the oddest looking thing you'll see in this book. But please bear with, it is not as scary as it looks! Furthermore, it is super useful. We use the pipe to send objects into functions.

In the above examples, we calculated the mean of column `var1` from `mydata` by `mean(mydata$var1)`. With the pipe, we can rewrite this as:

```{r}
library(tidyverse)
mydata$var1 %>% mean()
```

Which reads: "Working with `mydata`, we select a single column called `var1` (with the `$`) **and then** calculate the `mean()`." The pipe becomes especially useful once the analysis includes multiple steps applied one after another. A good way to read and think of the pipe is **"and then"**.
This piping business is not standard R functionality and before using it in a script, you need to tell R this is what you will be doing.
The pipe comes from the "magrittr" package (Figure \@ref(fig:chap2-fig-pipe)), but loading the tidyverse will also load the pipe.
So library(tidyverse) initialises everything you need (no need to include library(magrittr) explicitly).


>To insert a pipe `%>%`, use the keyboard shortcut `Ctrl+Shift+M`.


With or without the pipe, the general rule "if the result gets printed it doesn't get saved" still applies. To save the result of the function into a new variable (so it shows up in the Environment), you need to add the name of the new variable with the assignment operator (`=`):

```{r}
mean_result = mydata$var1 %>% mean()
```



```{r chap2-fig-pipe, echo = FALSE, fig.cap="This is not a pipe. René Magritte inspired artwork by Stefan Milton Bache (creator of `%>%` in R). Image source: https://cran.r-project.org/web/packages/magrittr/vignettes/magrittr.html"}
knitr::include_graphics("images/chapter02/magrittr.png")
```


## Reading data into R

We mentioned before that once a table (e.g. from spreadsheet or database) gets read into R we start calling it a `tibble`. 
The most common format data comes to us in is CSV (comma separated values). 
CSV is basically an uncomplicated spreadsheet with no formatting or objects other than a single table with rows and columns (no worksheets or formulas).
Furthermore, you don't need special software to quickly view a CSV file - a text editor will do, and that includes RStudio.

For example, look at "example_data.csv" in the healthyr project's folder in Figure \@ref(fig:chap2-fig-examplecsv) (this is the Files pane at the bottom-right corner of your RStudio).

```{r chap2-fig-examplecsv, echo = FALSE, fig.cap="View or import a data file."}
knitr::include_graphics("images/chapter02/files_csv_example.png")
```

Clicking on a data file gives us two options: `View File` or `Import Dataset`. 
For very standard CSV files, we don't usually bother with the Import interface and just type in (or copy from a previous script):

```{r, eval = FALSE}
library(tidyverse)
example_data = read_csv("example_data.csv")
```

Without further arguments, `read_csv()` defaults to:

* values are delimited by commas (e.g., `id, var1, var2, ...`)
* numbers use decimal point (e.g., `4.12`), rather than decimal comma (e.g., `4,12`)
* the first line has column names (it is a "header")
* missing values are empty or denoted NA

If your file, however, is different to these, then the `Import Dataset` interface (Figure \@ref(fig:chap2-fig-examplecsv)) is very useful as it will give you the relevant `read_()` syntax with all the extra arguments filled in for you.

```{r chap02-fig-import-tool, echo = FALSE, fig.cap="Import: Some of the special settings your data file might have."}
knitr::include_graphics("images/chapter02/import_options.png")
```


```{r chap02-fig-import-code, echo = FALSE, fig.cap="After using the Import Dataset window, copy-paste the resulting code into your script."}
knitr::include_graphics("images/chapter02/code_preview.png")
```

After selecting the specific options for your import file (there is a friendly preview window too, so you can immediately see whether R understands the format of the your data file), DO NOT BE tempted to press the `Import` button. 
Yes, this will read in your dataset once, but means you have to redo the selections every time you come back to RStudio.
Do copy-paste the code it gives you (e.g., Figure \@ref(fig:chap02-fig-import-code)) into your R script - this way you can use it over and over again. 
Making sure all steps are recorded in scripts makes your workflow reproducible by your future self, colleagues, supervisors, extraterrestrials. 

>The `Import Dataset` can also help you to read in Excel, SPSS, Stata, or SAS files (instead of read_csv(), it will give you `read_excel()`, `read_sav()`, `read_stata()`, or `read_sas()).

If you've used R before or are trying to make sense of legacy scripts passed on to you by colleagues, you might see `read.csv()` rather than `read_csv()`. In short: `read_csv()` is faster and better, and in all new scripts that's what you should use. But in existing scripts that work and are tested, do not just start replacing `read.csv()` with `read_csv()`. The thing is, `read_csv()` handles categorical variables slightly differently ^[It does not silently convert strings to factors, i.e., it defaults to `stringsAsFactors = FALSE`. For those not familiar with the terminology here - don't worry, we will cover this in just a few sections.]. This means that an R script written using the `read.csv()` might not work as expected any more if just replaced with `read_csv()`.

> Do not start updating and possibly breaking existing R scripts by replacing base R functions with the tidyverse ones we show here. Do use the modern functions in any new code you write. 


### Reading in the Global Burden of Disease example dataset (short version)

In the next few chapters of this book, we will be using the Global Burden of Disease datasets. 
The Global Burden of Disease Study (GBD) is the most comprehensive worldwide observational epidemiological study to date. 
It describes mortality and morbidity from major diseases, injuries and risk factors to health at global, national and regional levels.
^[Global Burden of Disease Collaborative Network.
Global Burden of Disease Study 2017 (GBD 2017) Results.
Seattle, United States: Institute for Health Metrics and Evaluation (IHME), 2018.
Available from http://ghdx.healthdata.org/gbd-results-tool.]

GBD data are publicly available from their website. Table \@ref(tab:chap2-tab-gbd) and Figure \@ref(fig:chap2-fig-gbd) show a very high level version of the propject's data with just 3 variables: cause, year, deaths (number of people who die of each cause every year). Later, we will be using a longer dataset with different subgroups and we will show you how to summarise comprehensive datasets yourself.

```{r, message=F}
library(tidyverse)
gbd_short = read_csv("data/global_burden_disease_SHORT.csv")
```

```{r chap2-tab-gbd, echo = FALSE}
gbd_short %>% 
  mutate(deaths = prettyNum(deaths, big.mark = ",")) %>% 
  knitr::kable(booktabs = TRUE,
               linesep = c("", "", "\\addlinespace"),
               align = c("l", "c", "r"),
               caption = "Deaths per year from three broad disease categories (short version of the Global Burden of Disease example dataset).") %>% 
  kableExtra::kable_styling(font_size=8)
```

```{r chap2-fig-gbd, echo = FALSE, fig.cap="Causes of death from the Global Burden of Disease dataset (Table \\@ref(tab:chap2-tab-gbd)). Data on (B) is the same as (A) but stacked to show the total (sum) of all causes.", fig.height=6, fig.width=6}
source("1_source_theme.R")
library(patchwork)
p1 = gbd_short %>% 
  ggplot(aes(x = year, y = deaths/1e6, fill = cause, colour = cause)) +
  geom_point() +
  geom_line() +
  labs(x = "Year", y = "Deaths per year (millions)") +
  facet_wrap(~cause) +
  theme(legend.position = "none") +
  scale_y_continuous(limits = c(0, 50), expand = c(0, 0)) +
  geom_text(aes(label = (deaths/1e6) %>% round(0)), colour = "#525252", size = 3, vjust = -0.5)

p2 = gbd_short %>% 
  ggplot(aes(x = year, y = deaths/1e6, fill = cause, colour = cause)) +
  geom_col() +
  labs(x = "Year", y = "Deaths per year (millions)") +
  theme(legend.position = "top") +
  scale_y_continuous(limits = c(0, 60), expand = c(0, 0)) +
  scale_x_continuous(breaks = unique(mydata$year)) +
  guides(fill=guide_legend(ncol=3))

p1/p2 + plot_annotation(tag_levels = "A")


```

\clearpage

## Operators for filtering data

Operators are symbols that tell R how to handle different pieces of data or objects.
We have already introduced three: `$` (selects a column), `=` (assignes values or results to a variable), and the pipe - `%>%` (sends data into a function).

Other common operators are the ones we use for filtering data - these are called comparison and logical operators.
This may be for creating subgroups, or for excluding outliers or incomplete cases.

The comparison operators that work with numeric data are relatively straightforward: `>, <, >=, <=`.
The first two check whether your values are greater or less than another value, the last two check for "greater than or equal to" and "less than or equal to. These opreators are most commonly spotted inside the `filter()` function:

```{r}
gbd_short %>% 
  filter(year < 1995)
```
Here we send the data (`gbd_short`) to the `filter()` and ask it to retain all years that are less than 1995.
The resulting tibble only includes the year 1990.
Now, if we use the `<=` (less than or equal to) operator, both 1990 and 1995 pass the filter:
```{r}
gbd_short %>% 
  filter(year <= 1995)
```

Furthermore, the values either side of the operator could both be variables, e.g., `mydata %>% filter(var2 > var1)`.

To filter for values that are equal to something, we use the `==` operator. For example, the first filtering example was actually equivalent to:

```{r}
gbd_short %>% 
  filter(year == 1995)
```

Accidentally using the single equals (`=` so the assignment operator) is a very common mistake and still ocasionally happens to the best of us.
In fact, it happens so often that the error the `filter()` function gives when using the wrong one also reminds us what the correct one was

```{r, error = TRUE}
gbd_short %>% 
  filter(year = 1995)
```

> The answer to 'do you need ==?" is almost always "Yes R, I do, thank you".

But that's just because `filter()` is a clever cookie and used to this very common mistake.
There are other useful functions we use these operators in, but they don't always know to tell us that we've just confused `=` for `==`.
So whenever checking for equality of variables but the result is not what you expect (you'll get an Error, but not necessary with the same wording as above), remember to check your `==` operators first.

R also has two operators for combining multiple comparisons: & and |, which stand for AND and OR, respectively.
For example, we can filter to only keep the earliest and latest years in the dataset:

```{r}
gbd_short %>% 
  filter(year == 1995 | year == 2017)
```

This reads: take the GBD dataset, send it to the filter to keep rows where year is equal to 1995 or year is equal to 2017.
Using specific values like we've done there (1995/2017) is called "hard-coding", which is fine if we know for sure we don't want to apply the same script on an updated dataset. But a cleverer way of achieving the same thing is to use the `min()` and `max()` functions:

```{r}
gbd_short %>% 
  filter(year == max(year) | year == min(year))
```



```{r chap2-tab-filtering-operators, echo = FALSE}
Operators = c("==", "!=" ,"<", ">", "<=", ">=", "&", "|")
Meaning   = c("Equal to", "Not equal to", "Less than", "Greater than", "Less than or equal to", "Greater then or equal to", "AND", "OR")

testdata = tibble(Operators, Meaning)

testdata %>% 
    knitr::kable(booktabs = TRUE,
               linesep = c(rep("", 6), "\\addlinespace"),
               align = c("l", "c", "r"),
               caption = "Filtering operators.") %>% 
  kableExtra::kable_styling(font_size=8)

```

| Symbol  | What does  | Example  | Example result|
|-------- | ---------  | -------- |-------|
| `%>% `   | sends data into a function | `x %>% print()` | 2 |
| `::`     | indicates package | `dplyr::count()` | `count()` fn. from the `dplyr` package|
| `->`            | assigns | `2 -> x` | the value of x is now 2 |

| `%in%`          | is value in list | `x %in% c(1,2,3)` | TRUE |
| `$`             | select a column | `mydata$year` | 1990,1996,...|
| `c()`           | combines values | `c(1, 2)`     | 1, 2 |
| `#`               | comment| `#Riinu changed this` | ignored by R   |



### Worked examples

Filter the dataset to only include the year 2000. Save this in a new variable using the assignment operator.

```{r, echo = TRUE}

mydata_year2000 = gbd_short %>% 
  filter(year == 2000)

```

Let's practice combining multiple selections together.

Reminder: '|' means OR and '&' means AND.

From `gbd_short`, select the lines where year is either 1990 or 2017 and cause is "Communicable diseases":

```{r}

new_data_selection = gbd_short %>% 
  filter((year == 1990 | year == 2013) & cause == "Communicable diseases")

# Or we can get rid of the extra brackets around the years
# by moving cause into a new filter on a new line:

new_data_selection = gbd_short %>% 
  filter(year == 1990 | year == 2013) %>% 
  filter(cause == "Communicable diseases")
```

## Missing values (NAs) and filters

Filtering for missing values (NAs) needs your special attention and care.
Remember the small example tibble from Table \@ref(tab:chap2-tab-examp1) - it has some NAs in columns `var2` and `var3`:

```{r}
mydata
```


If we now want to filter for rows where `var2` is missing, `filter(var2 == NA)` is not the way to do it, it will not work. 
Since R is a programming language, it can be a bit stubborn with things like these.
When you ask R to do a comparison using `==` (or `<`, `>`, etc.) it expects a value on each side, but NA is not a value, it is the lack thereof.
The way to filter for missing values is using the `is.na()` function:

```{r}
mydata %>% 
  filter(is.na(var2))
```
We send `mydata` to the filter and keep rows where `var2` is `NA`. 
Note the double brackets at the end: that's because the inner one belongs to `is.na()`, and the outer one to `filter()`.
Missing out a closing bracket is also a very common source of (minor, easily fixed) mistakes, and it still happens to the best of us.

If filtering for rows where `var2` is not missing, we do this:

```{r}
mydata %>% 
  filter(! is.na(var2))
```

In R, the exclamation mark (!) means "not".

Sometimes you want to drop a specific value (e.g. an outlier) from the dataset like this. The small example tibble `mydata` has 4 rows, with the values for `var2` as follows: `r mydata$var2`. We can exclude the row where `var2` is equal to 5 by using the "not equals (`!=`)^[ `filter(var2 != 5) is equivalent to filter(! var2 == 5)`]:

```{r}
mydata %>% 
  filter(var2 != 5)
```

However, you'll see that by doing this, R drops the rows where `var2` is NA as well, as it can't be sure these missing values were not equal to 5.

If you want to keep missing values, but still drop an outlier, you need to make use of the OR (`|`) operator and the `is.na()` function:

```{r}
mydata %>% 
  filter(var2 != 5 | is.na(var2))
```

Being caught out by missing values, either in filters or other functions is very common (remember mydata$var2 %>% mean() returns NA unless you add `na.rm = TRUE`). This is also why we insist that you always plot your data first - outliers will reveal themselves and NA values usually become obivious too.

Another thing we do to stay safe around filters and missing values is saving the results and making sure the number of rows still add up:

```{r}
subset1 = mydata %>% 
  filter(var2 == 5)

subset2 = mydata %>% 
  filter(! var2 == 5)

subset1
subset2
```

If the numbers are small, you can now quickly look at RStudio's Environment tab and figure out whether the number of observations (rows) in `subset1` and `subset2` add up to the whole dataset (`mydata`). Or use the `nrow()` function to as R to tell you what the number of rows is in each dataset:

Rows in `mydata`:

```{r}
nrow(mydata)
```

Rows in `subset1`:
```{r}
nrow(subset1)
```

Rows in `subset2`:
```{r}
nrow(subset2)
```

Asking R whether adding these two up equals the original size:

```{r}
nrow(subset1) + nrow(subset2) == nrow(mydata)
```



## Types of variables

```{r}

mydata = gbd_short
```


**consider structuring as per here: https://finalfit.org/articles/data_prep.html - AGREED, will do asap**

Like many other types of statistical software, R needs to know the variable type of each column. The main types are:

### Characters

**Characters** (sometimes referred to as *strings* or *character strings*) in R are letters, words, or even whole sentences (an example of this may be free text comments). 
We can specify these using the `as.character()` function. Characters are displayed in-between `""` (or `''`).

### Factors

**Factors** are fussy characters. 
Factors are fussy because they have something called levels. 
Levels are all the unique values this variable could take - e.g. like when we looked at `mydata$cause %>% unique()`.
Using factors rather than just characters can be useful because:


* The values factor levels can take is fixed. 
For example, if the levels of your column called `sex` are "Male" and "Female" and you try to add a new patient where sex is called just "F" you will get a warning from R. 
If `sex` was a character column rather than a factor R would have no problem with this and you would end up with "Male", "Female", and "F" in your column.
* Levels have an order. 
When we plotted the different causes of death in the last session, R ordered them alphabetically (because `cause` was a character rather than a factor). 
But if you want to use a non-alphabetical order, e.g. "Communicable diseases"-"Non-communicable diseases"-"Injuries", we need make `cause` into a factor. 
Making a character column into a factor enables us to define and change the order of the levels. 
Furthermore, there are useful tools such as `fct_inorder` or `fct_infreq` that can order factor levels for us.


These can be huge benefits, especially as a lot of medical data analyses include comparing different risks to a reference level. 
Nevertheless, the fussiness of factors can sometimes be unhelpful or even frustrating. 
For example, if you really did want to add a new level to your `gender` column (e.g., "Prefer not to say") you will either have to convert the column to a character, add it, and convert it back to a factor, or use `fct_expand` to add the level and then add your new line.

#### Exercise

Temporarily type `fct_inorder` anywhere in your script, then press F1. 
Read the **Description** in the Help tab and discuss with your neighbour how `fct_inorder` and `fct_infreq` would order your factor levels.


### Numbers

Self-explanatory! 
These are numbers. 
In R, we specify these using the `as.numeric()` function. 
Numbers without decimal places are sometimes called integers. 
Click on the blue arrow in front of `mydata` in the Environment tab and see that `year` is an `int` (integer) whereas `deaths` is a `num` (numeric).




### Specifying variable types

```{r, eval = FALSE}

as.character(mydata$cause)

as.numeric(mydata$year)

factor(mydata$year)

#Lets save the cause as a factor

mydata$cause = factor(mydata$cause)

#Now lets print it out

mydata$cause

```

### Exercise

Change the order of the levels in `mydata$cause` so that "Non-communicable diseases" come before "Injuries". 
Hint: use F1 to investigate examples of how `fct_relevel()` works.



## Adding columns to dataframes

If we wanted to add in a new column or variable to our data, we can simply use the dollar sign '$' to create a new variable inside a pre-existing piece of data:

```{r}

mydata$new = 1

mydata$new2 = 1:21

```

Run these lines and click on `mydata` in the Environment tab to check this worked as expected.

Conversely, if we want to delete a specific variable or column we can use the 'NULL' function, or alternatively ask R to `select()` the data without the new variable included.

```{r}

mydata$new = NULL

mydata = mydata %>% 
  select(-new2)

```

We can make new variables using calculations based on variables in the data too.

The mutate function is useful here. 
All you have to specify within the mutate function is the name of the variable (this can be new or pre-existing) and where the new data should come from.

There are two equivalent ways of defining new columns based on a calculation with a previous column:

**mutate formally introduced in later chapter. Need to think how best to present this in book.**

```{r}

# First option

mydata$years_from_1990 = mydata$year - 1990 
mydata$deaths_millions = mydata$deaths/1000000

# Second option (mutate() function)

mydata = mydata %>% 
  mutate(years_from_1990 = year-1990,
         deaths_millions = deaths/1000000) 

```

Throughout this course we will be using both of these ways to create or modify columns. 
The first option (using the `$`) can look neater when changing a single variable, but when combining multiple ones you will end up repeating `mydata$`. 
`mutate()` removes the duplication, but it does add a new line and brackets. 


## Rounding numbers

We can use `round()` to round the new variables to create integers.

### Exercise

Round the new column `deaths_millions` to no decimals:

```{r, echo = FALSE}

mydata$deaths_millions = round(mydata$deaths_millions)

mydata$deaths_millions

```

* How would you round it to 2 decimals? Hint: use F1 to investigate `round()`. 

* What do `ceiling()` and `floor()` do? Hint: sometimes you want to round a number up or down.

## The combine function: c()

The combine function combines several values: `c()`

The combine function can be used with numbers or characters (like words or letters):

```{r}

examplelist = c("Red", "Yellow", "Green", "Blue")

# Ask R to print it by executing it on its own line

examplelist

```

### Exercise

There are 18 lines (observations) in mydata. 
Create a new variable using `c()` with 18 values (numbers, words, whichever you like, e.g. like we created `examplelist`). 
Then add it as new column to `mydata$newlist`. 
Advanced version: do this using a combination of `rep()` and `c()`.

\newpage
## The `paste()` function

The `paste()` function is used to paste several words or numbers into one character variable/sentence.

In the paste function we need to specify what we would like to combine, and what should separate the components. 
By default, the separation is a space, but we can change this using the `sep =` option within the paste function.

So, for example if we wanted to make a sentence:

```{r pasteexample1}

# 
#paste("Edinburgh", "is", "Great")

# Lets add in full stops


paste("Edinburgh", "is", "Great", sep = ".")
# separator needs to go in "" as it is a character


# If we really like Edinburgh

#paste("Edinburgh", "is", "Great", sep = "!")

# If we want to make it one word

#paste("Edinburgh", "is", "Great", sep = "") # no separator (still need the brackets)

```

We can also join two different variables together using `paste()`: 


```{r pasteexample2}

paste("Year is", mydata$year)

```


### Exercise

Fix this code:

Hint: Think about characters and quotes!

```{r, eval=F}

paste(Today is, Sys.Date() )

```


## Combining two dataframes

For combining dataframes based on shared variables we use the joins: `left_join()`, `right_join()`, `inner_join()`, or `full_join()`. 
Let's split some of the variables in `mydata` between two new dataframes: `first_data` and `second_data`. 
For demonstrating the difference between the different joins, we will only include a subset (first 6 rows) of the dataset in `second_data`:

```{r, message = FALSE}

first_data  = select(mydata, year, cause, deaths_millions)
second_data = select(mydata, year, cause, deaths_millions) %>% slice(1:6)

# change the order of rows in first_data to demosntrate the join does not rely on the ordering of rows:
first_data = arrange(first_data, deaths_millions)

combined_left  =  left_join(first_data, second_data)
combined_right = right_join(first_data, second_data)
combined_inner = inner_join(first_data, second_data)
combined_full  =  full_join(first_data, second_data)


```

Those who have used R before, or those who come across older scripts will have seen `merge()` instead of the joins. 
`merge()` works similarly to joins, but instead of having the four options defined clearly at the front, you would have had to use the `all = FALSE, all.x = all, all.y = all` arguments.

![](images/databasejoke.jpg)

### Exercise

Investigate the four new dataframes called `combined_` using the Environment tab and discuss how the different joins (left, right, inner, full) work.


## The `summary()` function

In R, the `summary()` function provides a quick way of summarising both data or the results of statistical tests.

Lets get a quick summary of all the variables inside the Global Burden of Disease dataset. 
It will work for whole datasets and single variables too.

```{r}

mydata %>% summary()

```

This even works on statistical tests (we will learn more about these later):

```{r}

# lm stands for linear model
lm(deaths ~ year, data = mydata) %>% summary()

```

### When pipe sends data to the wrong place

Note that our usual way of doing things with the pipe would not work here:


```{r, eval = FALSE}

mydata %>% 
  lm(deaths ~ year) %>%
  summary()

```

This is because the pipe tries to send data into the first place of the function (first argument), but `lm()` wants the formula (`deaths ~ year`) first, then the dataframe. 
We can bypass this using `data = .` to tell the pipe where to put mydata:

```{r, eval = FALSE}

mydata %>% 
  lm(deaths ~ year, data = .) %>%
  summary()

```


### Exercise

Try adding a new variable called `death_over_10m` which indicates whether there were more than 10 million deaths for a cause. 
The new variable should take the form 'Yes' or 'No'. 

Then make it into a factor.

Then use `summary()` to find out about it!
```{r}

mydata = mydata %>% 
  mutate(death_over_10m = ifelse(deaths >= 10000000, "Yes", "No")) # Using ifelse

mydata$death_over_10m = as.factor(mydata$death_over_10m)

mydata$death_over_10m %>% summary()

```

## Extra: Creating a dataframe from scratch

It is rare that you will need to create a data frame by hand as most of the time you will be reading in a data from a .csv or similar. 
But in some cases (e.g. when creating special labels for a plot) it might be useful, so this is how to create one:


```{r}

patient_id = paste0("ID", 1:10)
sex        = rep(c("Female", "Male"), 5)
age        = 18:27

newdata = data_frame(patient_id, sex, age)

# same as

newdata      = data_frame(
  patient_id = paste0("ID", 1:10), #note the commas
  sex        = rep(c("Female", "Male"), 5),
  age        = 18:27
)


```


If we used `data.frame()` instead of `data_frame()`, all our character variables (`patient_id`, `sex`) would become factors automatically. 
This might make sense for `sex`, but it doesn't for `patient_id`.

### Exercise

Create a new dataframe called `my_dataframe` that looks like this:

Hint: Use the functions `paste0()`, `seq()` and `rep()`


```{r, echo=F}

my_dataframe = data_frame(
  patient_id = paste0("ID", 11:20),
  age        = seq(15, 60, 5),
  sex        = c( rep("Male", 5), rep("Female", 5))
)

my_dataframe

```


## Solutions

**2.5.3**

```{r, eval = FALSE}

mydata %>% names()
mydata %>% head()
mydata %>% str()

```

**2.5.4**

```{r}

mydata$cause %>% unique() %>% length()

```

**2.6.2**

```{r}

mydata_year2000 = mydata %>% 
  filter(year == 2000)

```

**2.7.5** 

```{r, eval = FALSE}
mydata$cause %>% fct_relevel("Injuries", after = 1)
```

**2.10.1**

```{r, message = FALSE}
mydata$deaths_millions = round(mydata$deaths_millions)

# or
mydata$deaths_millions = mydata$deaths_millions %>% round()


```

**2.11.1**

```{r}

examplelist = c("Red", "Yellow", "Green", "Blue",
                "Red", "Yellow", "Green", "Blue",
                "Red", "Yellow", "Green", "Blue",
                "Red", "Yellow", "Green", "Blue",
                "Red", "Yellow", "Green", "Blue",
                "Green")

#Let's see what we've made by using print

mydata$newlist = examplelist


# using rep()

#examplelist2 = rep(c("Green", "Red"), 9)

```


**2.12.1**

```{r, eval = FALSE}
paste("Today is", Sys.Date())
```

**2.15.1**

```{r}

my_dataframe = data_frame(
  patient_id = paste0("ID", 11:20),
  age        = seq(15, 60, 5),
  sex        = c( rep("Male", 5), rep("Female", 5))
)

```
